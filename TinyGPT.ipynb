{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "whvcVjQ0hErW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OL4NQxu-Nsu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the data**"
      ],
      "metadata": {
        "id": "LQWtRV27hI29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = open('data.txt', 'r').read().splitlines()\n",
        "data = [str(line.encode('ascii', 'ignore'), 'utf-8') for line in data]"
      ],
      "metadata": {
        "id": "C2-Z5lvo-4yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Char/idx - idx/char mapping**"
      ],
      "metadata": {
        "id": "V-qM4qEMhNek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char = list(set(''.join(data)))\n",
        "char_to_idx = {char: idx+1 for idx, char in enumerate(sorted(char))}\n",
        "char_to_idx['\\n'] = 0\n",
        "idx_to_char = {v: k for k, v in char_to_idx.items()}"
      ],
      "metadata": {
        "id": "8YxMT79V-6dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vocabulary size**"
      ],
      "metadata": {
        "id": "a_bwYjTrhRYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(idx_to_char)"
      ],
      "metadata": {
        "id": "flM8-QZuhRDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare data**"
      ],
      "metadata": {
        "id": "2X1KlCzXhUhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = ''.join([line+'\\n' for line in data])"
      ],
      "metadata": {
        "id": "pLcVfXRkKpYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode/Decode functions**"
      ],
      "metadata": {
        "id": "FJD0VxzihZOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(data):\n",
        "  return [char_to_idx[character] for character in data]\n",
        "\n",
        "def decode(data):\n",
        "  return ''.join([idx_to_char[idx] for idx in data])"
      ],
      "metadata": {
        "id": "6QPE7SAs-8CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset function**"
      ],
      "metadata": {
        "id": "4wx84uuvhc52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data=data, test=False):\n",
        "\n",
        "  data = torch.tensor(encode(data))\n",
        "  if test:\n",
        "    n = int(0.9*len(data))\n",
        "    X_train, X_test = data[:n], data[n:]\n",
        "    return X_train, X_test\n",
        "  else:\n",
        "    X_train = data\n",
        "    return X_train"
      ],
      "metadata": {
        "id": "URzwkCfR-9fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get batch function**"
      ],
      "metadata": {
        "id": "4nhQMo-Lhe1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data):\n",
        "    idx = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE, 1))\n",
        "    x = torch.stack([data[i:i+BLOCK_SIZE] for i in idx])\n",
        "    y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in idx])\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "hk2HMoTs--aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "6c_J1hUahjHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BLOCK_SIZE = 256\n",
        "MAX_ITERS = 3000\n",
        "LR = 3e-4\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EMB_SIZE = 576\n",
        "HEAD_NUM = 6\n",
        "HEAD_SIZE = 96\n",
        "LAYERS_NUM = 6\n",
        "DROPOUT = 0.2"
      ],
      "metadata": {
        "id": "BdbrehgCJj5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self attention**"
      ],
      "metadata": {
        "id": "ecN2Dci5h6B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, HEAD_SIZE):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(EMB_SIZE, HEAD_SIZE, bias=False)\n",
        "        self.query = nn.Linear(EMB_SIZE, HEAD_SIZE, bias=False)\n",
        "        self.value = nn.Linear(EMB_SIZE, HEAD_SIZE, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        scores = q @ k.transpose(-2,-1) * C**-0.5\n",
        "        scores = scores.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = scores @ v\n",
        "        return out"
      ],
      "metadata": {
        "id": "65CFTqAkh7Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multilayer perceptron**"
      ],
      "metadata": {
        "id": "MjaLHi03iBWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, EMB_SIZE):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(EMB_SIZE, 4 * EMB_SIZE),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * EMB_SIZE, EMB_SIZE),\n",
        "            nn.Dropout(DROPOUT),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "FbeSm2CeiDRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block**"
      ],
      "metadata": {
        "id": "IVTLaMZriEzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, EMB_SIZE, HEADS_NUM):\n",
        "        super().__init__()\n",
        "\n",
        "        self.heads = nn.ModuleList([Attention(HEAD_SIZE) for _ in range(HEADS_NUM)])\n",
        "        self.projection = nn.Linear(HEAD_SIZE * HEADS_NUM, EMB_SIZE)\n",
        "\n",
        "        self.mlp = MLP(EMB_SIZE)\n",
        "        self.ln1 = nn.LayerNorm(EMB_SIZE)\n",
        "        self.ln2 = nn.LayerNorm(EMB_SIZE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + torch.cat([h(self.ln1(x)) for h in self.heads], dim=-1)\n",
        "        x = self.projection(x)\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "HfjsiIKiiEkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Model**"
      ],
      "metadata": {
        "id": "K170ndfniMgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, EMB_SIZE)\n",
        "        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, EMB_SIZE)\n",
        "        self.blocks = nn.Sequential(*[Block(EMB_SIZE, HEAD_NUM) for _ in range(LAYERS_NUM)])\n",
        "        self.ln_f = nn.LayerNorm(EMB_SIZE)\n",
        "        self.lm_head = nn.Linear(EMB_SIZE, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        token_emb = self.token_embedding_table(idx)\n",
        "        position_emb = self.position_embedding_table(torch.arange(T, device=DEVICE))\n",
        "        x = token_emb + position_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -BLOCK_SIZE:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ],
      "metadata": {
        "id": "frC1pbY4iLD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create dataset**"
      ],
      "metadata": {
        "id": "g_VZJNnktpe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = create_dataset(test=True)"
      ],
      "metadata": {
        "id": "CyMmE5iyRzie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create model**"
      ],
      "metadata": {
        "id": "Sw0Mqc28tuHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT()\n",
        "m = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "TylBsO_5D53w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check number of parameters**"
      ],
      "metadata": {
        "id": "mmAc5XO-tyTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDUz6Wn2D61F",
        "outputId": "bf258f1e-6206-4489-da69-7cb40368acda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.164433 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "_gIh7hhEt1hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "MArsjZi_D7lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(MAX_ITERS):\n",
        "    xb, yb = get_batch(X_train)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (iter+1) % 250 == 0:\n",
        "      test_loss = []\n",
        "      for _ in range(100):\n",
        "        xb_test, yb_test = get_batch(X_test)\n",
        "        logits, loss = m(xb_test, yb_test)\n",
        "        test_loss.append(loss.item())\n",
        "      print(f'Test loss for the {iter+1}th iter is: {sum(test_loss) / len(test_loss)}')\n"
      ],
      "metadata": {
        "id": "Ug27ILPoECgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate from the model**"
      ],
      "metadata": {
        "id": "EL1kdTb7t3kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n",
        "print(decode(m.generate(context, max_new_tokens=5000)[0].tolist()))"
      ],
      "metadata": {
        "id": "vHUXII2gFzSP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}